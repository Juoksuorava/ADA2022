{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Nested cross-validation exercise\n",
    "\n",
    "## Nested cross-validation for k-nearest neighbors <br>\n",
    "- Use Python 3 to program a nested leave-one-out cross-validation for the k-nearest neighbors (kNN) method so that the number of neighbours k is automatically selected from the set k = [3, 5, 7, 9, 11]. In other words, the base learning algorithm is kNN but the actual learning algorithm, whose prediction performance will be evaluated with nested CV, is kNN with automatic CV-based model selection (see the lectures and the pseudo codes presented on them for more info on this interpretation). \n",
    "- Compare the C-index produced by nested leave-one-out CV with normal leave-one-out cross-validation with the best value of k.  \n",
    "- As a kNN implementation, use the provided kNN and C-index functions in your exercise.\n",
    "- Use the CV implementations on the provided subsampled iris data (100 randomly drawn data points from iris) and report the resulting classification accuracy via C-index. Hint: you can use the nested CV example provided on sklearn documentation: https://scikit-learn.org/stable/auto_examples/model_selection/plot_nested_cross_validation_iris.html as a starting point, but do NOT use the ready made CV implementations of sklearn.\n",
    "\n",
    "As a summary, for completing this exercise implement the following steps: \n",
    "_______________________________________________________________\n",
    "#### 1. Use leave-one-out cross-validation for determining the optimal k-parameter for the data (X.csv, y.csv) from the set k = [3,5,7,9,11]. When you have solved the optimal k-parameter, save the corresponding C-index (call it loo_c_index) for this best value of k.\n",
    "#### 2. Similarly, use nested leave-one-out cross-validation (leave-one-out both in outer and inner folds) for determining the C-index (call it nloo_c_index) of the kNN + leave-one-out cross-validation based k selection  approach. \n",
    "#### 3. Return both this notebook and as a PDF-file made from it in the exercise submit page. \n",
    "_______________________________________________________________\n",
    "\n",
    "Remember to use the provided C-index and kNN functions in your implementation! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.5, 3. , 5.2, 2. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [5.7, 2.8, 4.5, 1.3]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[2.],\n",
       "       [1.],\n",
       "       [2.],\n",
       "       [0.],\n",
       "       [1.]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#In this cell import all libraries you need. For example: \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.model_selection\n",
    "from IPython.display import display\n",
    "\n",
    "X = pd.read_csv('data/X.csv', header=None).to_numpy()\n",
    "y = pd.read_csv('data/y.csv', header=None).to_numpy()\n",
    "display(X[:5], len(X))\n",
    "display(y[:5], len(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provided functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "C-index function: \n",
    "- INPUTS: \n",
    "'y' an array of the true output values\n",
    "'yp' an array of predicted output values\n",
    "- OUTPUT: \n",
    "The c-index value\n",
    "\"\"\"\n",
    "def cindex(y, yp):\n",
    "    n = 0\n",
    "    h_num = 0 \n",
    "    # display(len(y))\n",
    "    # display(len(yp))\n",
    "    for i in range(0, len(y)):\n",
    "        t = y[i]\n",
    "        p = yp[i]\n",
    "        for j in range(i+1, len(y)):\n",
    "            nt = y[j]\n",
    "            np = yp[j]\n",
    "            if (t != nt): \n",
    "                n = n + 1\n",
    "                if (p < np and t < nt) or (p > np and t > nt): \n",
    "                    h_num += 1\n",
    "                elif (p == np):\n",
    "                    h_num += 0.5\n",
    "    return h_num/n\n",
    "\n",
    "\"\"\"\n",
    "Self-contained k-nearest neighbor\n",
    "- INPUTS: \n",
    "'X_train' a numpy matrix of the X-features of the train data points\n",
    "'y_train' a numpy matrix of the output values of the train data points\n",
    "'X_test' a numpy matrix of the X-features of the test data points\n",
    "'k' the k-parameter integer value for kNN\n",
    "- OUTPUT: \n",
    "'y_predictions' a list of the output value predictions\n",
    "\"\"\"\n",
    "def knn(X_train, y_train, X_test, k):\n",
    "    y_train = np.array(y_train, dtype=int)\n",
    "    y_predictions = []\n",
    "    for test_ind in range(0, X_test.shape[0]):\n",
    "        diff = X_test[test_ind, :].reshape(1, -1) - X_train\n",
    "        distances = np.sqrt(np.sum(diff * diff, axis = 1))\n",
    "        sort_inds = np.array(np.argsort(distances), dtype=int)\n",
    "        counts = np.bincount(y_train[sort_inds[0:k]])\n",
    "        y_predictions.append(np.argmax(counts))\n",
    "    return y_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Your implementation here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Determine optimal k-parameter using LOOCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k-parameters from kSet=[3, 5, 7, 9, 11] is 5 with C-index score of 0.9746474647464747\n"
     ]
    }
   ],
   "source": [
    "# Find best k-parameter for data X using C-index score as evaluator\n",
    "def calculate_best_k(X, y):\n",
    "    # List for k-parameters\n",
    "    kSet = [3, 5, 7, 9, 11]\n",
    "    # Variable for best k\n",
    "    best_k = kSet[0]\n",
    "    best_score = 0\n",
    "    # For all k-parameters\n",
    "    for k in kSet:\n",
    "        # List for predicted values\n",
    "        preds = []\n",
    "        # For all rows in data\n",
    "        for i in range(len(X)):\n",
    "            # Choose the ith row as test set and exclude ith row from train sets\n",
    "            X_test = X[i].reshape(1, -1)\n",
    "            X_train = np.delete(X, i, axis = 0) \n",
    "            y_train = np.delete(y, i, axis = 0).reshape(-1)\n",
    "            # Basic kNN prediction making and saving to our predictions list\n",
    "            pred = knn(X_train, y_train, X_test, k)\n",
    "            preds.append(pred)\n",
    "        # Calculate C-index score with our predictions\n",
    "        score = cindex(y, preds)\n",
    "        # Replace best k-parameter if score is higher than current highest score\n",
    "        if (score > best_score):\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "    # Return best k-parameter and highest score\n",
    "    return best_k, best_score\n",
    "\n",
    "best_k, best_score = calculate_best_k(X, y)\n",
    "print(\"Best k-parameters from kSet=[3, 5, 7, 9, 11] is\", best_k, \"with C-index score of\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Determine C-index of previous selection using NLOOCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find best k-parameter for data X using C-index score as evaluator\n",
    "def calculate_best_k(X, y):\n",
    "    # List for k-parameters\n",
    "    kSet = [3, 5, 7, 9, 11]\n",
    "    # Variable for best k\n",
    "    best_k = kSet[0]\n",
    "    best_score = 0\n",
    "    # For all k-parameters\n",
    "    for k in kSet:\n",
    "        # List for predicted values\n",
    "        preds = []\n",
    "        # For all rows in data\n",
    "        for i in range(len(X)):\n",
    "            # Choose the ith row as test set and exclude ith row from train sets\n",
    "            X_test = X[i].reshape(1, -1)\n",
    "            X_train = np.delete(X, i, axis = 0) \n",
    "            y_train = np.delete(y, i, axis = 0).reshape(-1)\n",
    "            # Basic kNN prediction making and saving to our predictions list\n",
    "            pred = knn(X_train, y_train, X_test, k)\n",
    "            preds.append(pred)\n",
    "        # Calculate C-index score with our predictions\n",
    "        score = cindex(y, preds)\n",
    "        # Replace best k-parameter if score is higher than current highest score\n",
    "        if (score > best_score):\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "    # Return best k-parameter and highest score\n",
    "    return best_k, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate C-index scores for data X using a nested leave-one-out cross-validation\n",
    "def calculate_scores_nested(X, y):\n",
    "    # List for C-index scores\n",
    "    scores = []\n",
    "    # For all rows in data\n",
    "    for i in range(len(X)):\n",
    "        # List for predicted values\n",
    "        preds = []\n",
    "        # Choose the ith row as test set and exclude ith row from train sets\n",
    "        X_test = X[i].reshape(1, -1)\n",
    "        X_train = np.delete(X, i, axis = 0) \n",
    "        y_train = np.delete(y, i, axis = 0).reshape(-1)\n",
    "        # Find best k-parameter for training set using our function\n",
    "        best_k, best_score = calculate_best_k(X_train, y_train)\n",
    "        # Basic kNN prediction making using our best k-parameter and saving to our predictions list\n",
    "        pred = knn(X_train, y_train, X_test, best_k)\n",
    "        preds.append(pred)\n",
    "        score = cindex(y, preds)\n",
    "        scores.append(score)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mh:\\ADA2022\\Exercise 1\\ADA2022_exercise1_Lauri_Orava.ipynb Cell 12'\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/ADA2022/Exercise%201/ADA2022_exercise1_Lauri_Orava.ipynb#ch0000010?line=0'>1</a>\u001b[0m \u001b[39m# Prepare variables\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/h%3A/ADA2022/Exercise%201/ADA2022_exercise1_Lauri_Orava.ipynb#ch0000010?line=1'>2</a>\u001b[0m nloocv_c_scores \u001b[39m=\u001b[39m calculate_scores_nested(X, y)\n\u001b[0;32m      <a href='vscode-notebook-cell:/h%3A/ADA2022/Exercise%201/ADA2022_exercise1_Lauri_Orava.ipynb#ch0000010?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mC-index average of LOOCV: \u001b[39m\u001b[39m\"\u001b[39m, np\u001b[39m.\u001b[39mmean(nloocv_c_scores))\n",
      "\u001b[1;32mh:\\ADA2022\\Exercise 1\\ADA2022_exercise1_Lauri_Orava.ipynb Cell 11'\u001b[0m in \u001b[0;36mcalculate_scores_nested\u001b[1;34m(X, y)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/ADA2022/Exercise%201/ADA2022_exercise1_Lauri_Orava.ipynb#ch0000009?line=15'>16</a>\u001b[0m     pred \u001b[39m=\u001b[39m knn(X_train, y_train, X_test, best_k)\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/ADA2022/Exercise%201/ADA2022_exercise1_Lauri_Orava.ipynb#ch0000009?line=16'>17</a>\u001b[0m     preds\u001b[39m.\u001b[39mappend(pred)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/h%3A/ADA2022/Exercise%201/ADA2022_exercise1_Lauri_Orava.ipynb#ch0000009?line=17'>18</a>\u001b[0m     score \u001b[39m=\u001b[39m cindex(y, preds)\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/ADA2022/Exercise%201/ADA2022_exercise1_Lauri_Orava.ipynb#ch0000009?line=18'>19</a>\u001b[0m     scores\u001b[39m.\u001b[39mappend(score)\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/ADA2022/Exercise%201/ADA2022_exercise1_Lauri_Orava.ipynb#ch0000009?line=19'>20</a>\u001b[0m \u001b[39mreturn\u001b[39;00m scores\n",
      "\u001b[1;32mh:\\ADA2022\\Exercise 1\\ADA2022_exercise1_Lauri_Orava.ipynb Cell 5'\u001b[0m in \u001b[0;36mcindex\u001b[1;34m(y, yp)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/ADA2022/Exercise%201/ADA2022_exercise1_Lauri_Orava.ipynb#ch0000004?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(i\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mlen\u001b[39m(y)):\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/ADA2022/Exercise%201/ADA2022_exercise1_Lauri_Orava.ipynb#ch0000004?line=17'>18</a>\u001b[0m     nt \u001b[39m=\u001b[39m y[j]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/h%3A/ADA2022/Exercise%201/ADA2022_exercise1_Lauri_Orava.ipynb#ch0000004?line=18'>19</a>\u001b[0m     np \u001b[39m=\u001b[39m yp[j]\n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/ADA2022/Exercise%201/ADA2022_exercise1_Lauri_Orava.ipynb#ch0000004?line=19'>20</a>\u001b[0m     \u001b[39mif\u001b[39;00m (t \u001b[39m!=\u001b[39m nt): \n\u001b[0;32m     <a href='vscode-notebook-cell:/h%3A/ADA2022/Exercise%201/ADA2022_exercise1_Lauri_Orava.ipynb#ch0000004?line=20'>21</a>\u001b[0m         n \u001b[39m=\u001b[39m n \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Prepare variables\n",
    "nloocv_c_scores = calculate_scores_nested(X, y)\n",
    "print(\"C-index average of LOOCV: \", np.mean(nloocv_c_scores))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
